{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"id":"CBRXrM4yVbRK"},"source":["# Setting up google drive \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8o6vaVOzVZd8"},"source":["import my_utils as mu\n","import torch\n","from torch import nn\n","from torch.nn import functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNH_cax4ONr8"},"source":["# The Task\n","\n","* Our **Task** for this week is to implement ResNet, the most widely-used Deep Learning architecture to date!\n","* The Learning Outcome: Hands-on application of PyTorch's API for creating Advanced CNNs.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"evMABFO3ONr8"},"source":["## Task 1: Implement the ResNet block\n","\n","* ResNet-18 uses extensively the so-called ResNet block which has a skip connection.\n","* The graphical illustration of the ResNet block is shown below.\n","* Your ResNet block should accept `input_channels` as input, and produce `output_channels` as ouput.\n","* As shown below, both Conv. layers within a ResNet block should have a kernel size $3 \\times 3$, and padding 1. The first Conv. layer should also accept a `stride` parameter which can be used to reduced spatial resolution. For example, if `stride=2`, the resolution will be halved. \n","* The right block is used when the number of channels in the input is not the same as the number of channels in the output.\n","    * An $1 \\times 1$ conv. layer is used to make them equal.     \n","* **Your task** is to create a single class called `Residual_block` that should handle both cases. \n","\n","![Left: regular ResNet block; Right: ResNet block with 1x1 convolution.](https://drive.google.com/uc?export=view&id=1oKGT5iabWYLT7pUlMZOCX4-Drr3IttVZ) \n"]},{"cell_type":"code","metadata":{"id":"eqeL0ywvONr8"},"source":["#Write your code for the class called Residual_block \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sKuM6BPkONr9"},"source":["## Task 2: Implement ResNet Macro-Block\n","\n","* ResNet-18 uses modules also called Macro-Blocks each of which contains 2 ResNet blocks. \n","\n","* In the first ResNet block within each Macro-Block, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n","\n","* In the second ResNet block, the number of channels remains the same.\n","* **Your task** is to implement a class called `Resnet_macro_block`. Your Macro-Block should accept `input_channels` as input, and produce `output_channels` as ouput."]},{"cell_type":"code","metadata":{"id":"J2zKaJxuONr9"},"source":["class Resnet_macro_block(nn.Module):\n","    def __init__(self, input_channels, output_channels, num_residuals, first_block=False):\n","        super(Resnet_macro_block, self).__init__()\n","        self.num_residuals = num_residuals\n","        for i in range(num_residuals):\n","            if i == 0 and not first_block:\n","                self.add_module('conv{0}'.format(i), \n","                                Residual_block(input_channels, output_channels, use_1x1conv=True, strides=2))\n","            else:\n","                self.add_module('conv{0}'.format(i), \n","                                Residual_block(output_channels, output_channels))\n","    def forward(self, x):\n","        out = x\n","        for i in range(self.num_residuals):\n","            out = self._modules['conv{0}'.format(i)](out)\n","        return out "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E660w9QEVZeP"},"source":["## Task 3: Implement ResNet-18 Architecture\n","\n","\n","* We will consider here the implementation of a slightly modified version of ResNet-18, appropriate for the input resolution of $32 \\times 32$.\n","* ResNet-18 has 1 stem and 4 macro-modules followed by 1 linear (FC) layer. \n","* Stem = simple processing unit with:\n","    * 1 standard conv. layer with kernel $3\\times 3$, stride 1, and number of output channels 64. It processes features at resolution 32 (input resolution).\n","    * A Batch-Norm layer.\n","    * A Relu.\n","* Each macro-module processes features in a different resolution. \n","     * Resolutions used are: 16, 8, 4, 2\n","* As mentioned above, the macro-modules are composed of the so-called ResNet blocks.\n","    * In ResNet-18, there are 2 ResNet blocks per macro-module.\n","* Each ResNet (Residual) block consists of 2 convolutions with skip connections.\n","* In total $1 + 4\\times2\\times2 + 1=18$ layers.\n","* **Your task** is to implement a class called `Resnet18`. A skeleton can be found below where the stem and the FC connected layer are provided.\n"]},{"cell_type":"code","metadata":{"id":"QMu3XAZxONr-"},"source":["class Resnet18(nn.Module):\n","    def __init__(self):\n","        super(Resnet18, self).__init__()\n","        self.stem = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n","                   nn.BatchNorm2d(64), nn.ReLU())\n","        self.b2 = Resnet_macro_block(64, 64, 1)\n","        self.b3 = Resnet_macro_block(64, 128, 1)\n","        self.b4 = Resnet_macro_block(128, 256, 1)\n","        self.b5 = Resnet_macro_block(256, 512, 1)\n","        self.last = nn.Sequential(nn.AdaptiveMaxPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10))\n","        \n","    def forward(self, x):\n","        #print(x.size())\n","        out = self.stem(x)\n","        #print(out.size())\n","        out = self.b2(out)\n","        #print(out.size())\n","        out = self.b3(out)\n","        #print(out.size())\n","        out = self.b4(out)\n","        #print(out.size())\n","        out = self.b5(out)\n","        #print(out.size())\n","        out = self.last(out)\n","        #print(out.size())\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"CQrbpBY8ONr_"},"source":["# Test your implementation here!\n","resnet18 = Resnet18()\n","batch_size = 256\n","train_iter, test_iter = mu.load_data_fashion_mnist(batch_size, resize=32)\n","train_iter2 = iter(train_iter)\n","x = next(train_iter2)\n","print(x[0].size())\n","y_hat = resnet18(x[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RuIL078VZeS","scrolled":true},"source":["# Training a ResNet18 on Fashion Mnist\n","lr, num_epochs, batch_size = 0.05, 10, 256\n","train_iter, test_iter = mu.load_data_fashion_mnist(batch_size, resize=32)\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(resnet18.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDn_dlxzU4wC"},"source":["\n","\n","## Switch to a GPU with Colab \n","\n","* Google colab offers free GPU training. Some of the available GPU types are Nvidia K80s, T4s, P4s and P100s. You can choose to train on a CPU or GPU but you can not choose what type of gpu you will be connected to at any given time.\n","\n","* To switch to GPU training you can either do: \n","    1. **Edit** ==> **Notebook settings** ==> **Hardware Accelerator (GPU)** ==> **Save** , or\n","    2. **Runtime** ==> **Change runtime type** ==> **Hardware Accelerator (GPU)** ==> **Save**\n","\n","* If you choose to train on a GPU you will have to restart colab. To do so, select **Runtime** and then choose **Restart and run all**.\n","\n","* Cast your model, input and labels to the GPU (already done below)\n"]},{"cell_type":"code","metadata":{"id":"sickwpz5VDCT"},"source":["def trainf(net, train_iter, test_iter, loss, num_epochs, optimizer, device):\n","    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n","    net.to(device)\n","    animator = mu.d2l.Animator(xlabel='epoch', xlim=[0, num_epochs],\n","                            legend=['train loss', 'train acc', 'test acc'])\n","    timer = mu.d2l.Timer()\n","    for epoch in range(num_epochs):\n","        metric = mu.d2l.Accumulator(3)  # train_loss, train_acc, num_examples\n","        for i, (X, y) in enumerate(train_iter):\n","            timer.start()\n","            net.train()\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            with torch.no_grad():\n","                metric.add(l*X.shape[0], mu.d2l.accuracy(y_hat, y), X.shape[0])\n","            timer.stop()\n","            train_loss, train_acc = metric[0]/metric[2], metric[1]/metric[2]\n","            if (i+1) % 50 == 0:\n","                animator.add(epoch + i/len(train_iter),\n","                              (train_loss, train_acc, None))\n","        test_acc = mu.evaluate_accuracy_gpu(net, test_iter)\n","        animator.add(epoch+1, (None, None, test_acc))\n","    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n","          f'test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n","          f'on {str(device)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1votYgZVFvm"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #choose device: cpu or gpu\n","print('Using device:', device)\n","if torch.cuda.is_available(): print(torch.cuda.get_device_name(0)) # print the type of the chosen gpu\n","trainf(resnet18, train_iter, test_iter, loss, num_epochs, optimizer, device)"],"execution_count":null,"outputs":[]}]}