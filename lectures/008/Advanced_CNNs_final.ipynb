{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CBRXrM4yVbRK"},"outputs":[],"source":["'''# Setting up google drive \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8o6vaVOzVZd8"},"outputs":[],"source":["import my_utils as mu\n","import torch\n","from torch import nn\n","from torch.nn import functional as F"]},{"cell_type":"markdown","metadata":{"id":"gOufsvkIVZeE","origin_pos":0},"source":["# Convolutional Neural Networks -- ImageNet\n","\n","* Deep models with many layers require large amounts of data in order to significantly outperform traditional methods (e.g., linear and kernel methods).\n","* Most research up until 2010 relied on tiny datasets.\n","\n","* In 2009, the ImageNet dataset was released, challenging researchers to learn models from 1 million examples, 1,000 each from 1,000 distinct categories of objects.\n","    * This scale was unprecedented.\n","    * The associated competition, dubbed the ImageNet Challenge pushed computer vision and machine learning research forward, challenging researchers to identify which models performed best at a greater scale than academics had previously considered."]},{"cell_type":"markdown","metadata":{"id":"zRoxGCZTVZeF"},"source":["# Convolutional Neural Networks -- GPU Processing\n","\n","* Training Deep learning models can take hundreds of epochs, and each iteration requires passing data through many layers of computationally-expensive linear algebra operations.\n","* This is one of the main reasons why in the 90s and early 2000s, simple algorithms based on linear and kernel methods were preferred.\n","* Graphical processing units (GPUs) proved to be a game changer in make deep learning feasible.\n","     * Orginally optimized for high throughput 4x4 matrix-vector products for  graphics tasks.\n","     * strikingly similar to what is required to calculate convolutional layers."]},{"cell_type":"markdown","metadata":{"id":"bRqJwyF5_nwS"},"source":["* Back to 2012: A major breakthrough came when Alex Krizhevsky and Ilya Sutskever implemented a deep convolutional neural network that could run on GPU hardware.\n","    * They realized that the computational bottlenecks in CNNs (convolutions and matrix multiplications) are all operations that could be parallelized in hardware.\n","* Using two NVIDIA GTX 580s with 3GB of memory, they implemented fast convolutions."]},{"cell_type":"markdown","metadata":{"id":"yEWBiMXTVZeF"},"source":["\n","# AlexNet\n","\n","* AlexNet was introduced in 2012, named after Alex Krizhevsky, the first author of the breakthrough ImageNet classification paper  \n","    * It won the ImageNet Large Scale Visual Recognition Challenge 2012 by a phenomenally large margin.\n","\n","* The architectures of AlexNet and LeNet are *very similar*\n","* There are also significant differences.\n","    * First, AlexNet is much deeper than the comparatively small LeNet5.\n","    * Second, AlexNet used the ReLU instead of the sigmoid "]},{"cell_type":"markdown","metadata":{"id":"rxZjEnaBVZeF"},"source":["\n","# AlexNet\n","\n","<!-- ![LeNet (left) and AlexNet (right)](img/alexnet.svg) -->\n","\n","![LeNet (left) and AlexNet (right)](https://drive.google.com/uc?export=view&id=1sAHdepTD1zhe8sF-0tl1eQqU3iTjAULT)\n","\n","* LeNet (left) and AlexNet (right)"]},{"cell_type":"markdown","metadata":{"id":"kjAt1Ts6VZeG"},"source":["# Concise Implementation of LeNet\n","\n","* Goal: use high-level APIs of PyTorch for implementing LeNet for classification. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFfuq2hZ_nwX"},"outputs":[],"source":["# Read training and test data\n","batch_size = 256\n","train_iter, test_iter = mu.load_data_fashion_mnist(batch_size, resize=224)\n","# type(train_iter)"]},{"cell_type":"markdown","metadata":{"id":"QCLNk35LVZeG"},"source":["# Defining the Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ3zqSxgVZeH"},"outputs":[],"source":["class AlexNet(torch.nn.Module):\n","    def __init__(self, num_outputs):\n","        super(AlexNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 96, 11, stride=4)\n","        self.rl1 = nn.ReLU() \n","        self.max1 = nn.MaxPool2d(3, stride=2)\n","        self.conv2 = nn.Conv2d(96, 256, 5, stride=1, padding=2)\n","        self.rl2 = nn.ReLU() \n","        self.max2 = nn.MaxPool2d(3, stride=2)\n","        \n","        self.conv3 = nn.Conv2d(256, 384, 3, 1, padding=1)\n","        self.rl3 = nn.ReLU() \n","        self.conv4 = nn.Conv2d(384, 384, 3, 1, padding=1)\n","        self.rl4 = nn.ReLU() \n","        self.conv5 = nn.Conv2d(384, 384, 3, 1, padding=1)\n","        self.rl5 = nn.ReLU() \n","        self.max3 = nn.MaxPool2d(3, stride=2)\n","\n","        self.fl = nn.Flatten()\n","        self.linear1 = nn.Linear(9600, 4096)\n","        self.rl6 = nn.ReLU() \n","        self.linear2 = nn.Linear(4096, 4096)\n","        self.rl7 = nn.ReLU() \n","        self.linear3 = nn.Linear(4096, num_outputs)\n","\n","    def forward(self, x):\n","        print(x.size())\n","        out = self.conv1(x)\n","        print(out.size())\n","        out = self.rl1(out)\n","        out = self.max1(out)\n","        print(out.size())\n","        out = self.conv2(out)\n","        print(out.size())\n","        out = self.rl2(out)\n","        out = self.max2(out)\n","        print(out.size())\n","        out = self.conv3(out)\n","        print(out.size())\n","        out = self.rl3(out)\n","        out = self.conv4(out)\n","        print(out.size())\n","        out = self.rl4(out)\n","        out = self.conv5(out)\n","        print(out.size())\n","        out = self.rl5(out)\n","        out = self.max3(out)\n","        print(out.size())\n","\n","        out = self.fl(out)\n","        out = self.linear1(out)\n","        out = self.rl6(out)\n","        out = self.linear2(out)\n","        out = self.rl7(out)\n","        out = self.linear3(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nypP5Igc_nwa"},"outputs":[],"source":["def init_weights(m):\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking type we can init different layers in different ways\n","        torch.nn.init.xavier_uniform_(m.weight)          \n","\n","num_outputs = 1000\n","net = AlexNet(num_outputs)\n","\n","net.apply(init_weights);\n","print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtlGf1Im_nwb"},"outputs":[],"source":["a = torch.rand(16, 1, 224, 224)\n","out = net(a)\n","print(out.size())"]},{"cell_type":"markdown","metadata":{"id":"zwXdo4KCVZeK"},"source":["# Loss and Optimization Algorithm\n","* As in Softmax Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-CmngurVZeK"},"outputs":[],"source":["loss = nn.CrossEntropyLoss()\n","lr = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"Jvc-s6zNVZeL"},"source":["# Training\n","\n","* Use `my_utils.train_ch3` as in Softmax Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ab26Ezc_VZeL","scrolled":false},"outputs":[],"source":["num_epochs = 10\n","mu.train_ch3(model, train_iter, test_iter, loss, num_epochs, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"txyus2L-VZeM"},"source":["# VGG\n","\n","<!-- ![Designing a network from building blocks.](img/vgg.svg)  -->\n","\n","![Designing a network from building blocks.](https://drive.google.com/uc?export=view&id=15ysfwZ-LbaSnZzd_lbeo2Iq5HYbR7WhY) \n"," \n","\n"]},{"cell_type":"markdown","metadata":{"id":"L9SsXuJeVZeM"},"source":["# VGG\n","\n","* Invented by the Visual Geometry Group in Oxford University\n","* The original VGG network had 5 convolutional blocks (VGG blocks)\n","    * The VGG block is the main building of the VGG network.\n","    * The first two have one convolutional layer each.\n","    * The latter three contain two convolutional layers each.\n","    * The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches $512$.\n","* Since this network uses $8$ convolutional layers and $3$ fully-connected layers, it is called VGG-11.\n","    * The deepest network trained has 19 layers (called VGG-19)."]},{"cell_type":"markdown","metadata":{"id":"IX7DyuEOVZeN"},"source":["# VGG block"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_HoAP9PVZeN"},"outputs":[],"source":["class VGG_block(nn.Module):\n","    def __init__(self, num_convs, input_channels, output_channels):\n","        super(VGG_block, self).__init__()\n","        self.num_convs = num_convs\n","        for i in range(num_convs):\n","            self.add_module('conv{0}'.format(i), nn.Conv2d(input_channels, \n","                                                           output_channels, kernel_size=3, padding=1))\n","            input_channels = output_channels\n","            self.add_module('relu{0}'.format(i), nn.ReLU())\n","            \n","        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        \n","    def forward(self, x):\n","        out = x\n","        for i in range(self.num_convs):\n","            out = self._modules['conv{0}'.format(i)](out)\n","            out = self._modules['relu{0}'.format(i)](out)\n","        \n","        out = self.max_pool(out)\n","        return out  "]},{"cell_type":"markdown","metadata":{"id":"XG8qDbk4VZeO"},"source":["# VGG-11"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESV4CRRfVZeO"},"outputs":[],"source":["class VGG(nn.Module):\n","    def __init__(self, conv_arch):\n","        super(VGG, self).__init__()\n","        in_channels = 1\n","        self.conv_arch = conv_arch\n","        for i, (num_convs, out_channels) in enumerate(conv_arch):\n","            self.add_module('vgg_block{0}'.format(i), VGG_block(num_convs, in_channels, out_channels))\n","            in_channels = out_channels\n","\n","        self.last = nn.Sequential(nn.Flatten(), nn.Linear(out_channels*7*7, 4096), \n","                                  nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), \n","                                  nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10))\n","        \n","    def forward(self, x):\n","        out = x\n","        for i in range(len(self.conv_arch)):\n","            out = self._modules['vgg_block{0}'.format(i)](out)\n","        out = self.last(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0U66iBT_nwk"},"outputs":[],"source":["conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n","net = VGG(conv_arch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bAHHjsJ_nwk"},"outputs":[],"source":["print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNWLctZ4VZeO","scrolled":true},"outputs":[],"source":["a = torch.rand(16, 1, 224, 224)\n","print(a.size())\n","out = net(a)\n","print(out.size())"]},{"cell_type":"markdown","metadata":{"id":"7pQXPV-dVZeP"},"source":["# ResNet\n","* Prior to ResNet, it was hard to train very deep networks\n","    * Depth facilitates learning very powerful networks\n","* Kaiming He solved this in his paper: *Deep Residual Learning for Image Recognition,* CVPR 2016\n","    * He showed how how to train networks with 152 convolutional layers!\n","    * The most popular computer vision paper ever written!\n","* Main idea: add the input feature $x$ to the output of a conv. layer $F$\n","    * $y = F(x) + x$\n","    * This is called **skip connection**\n","* The advantage is that thereâ€™s a direct path for propagating gradients during back-prop.\n"]},{"cell_type":"markdown","metadata":{"id":"VeT4eKGu_nwn"},"source":["# ResNet block\n","\n","* ResNet is similar to VGG but uses a ResNet block which has a skip connection.\n","    * The right block is used when the number of channels in the input is not the same as the number of channels in the output\n","         * An $1 \\times 1$ conv. layer is used to make them equal.\n","\n","<!-- ![Left: regular ResNet block; Right: ResNet block with 1x1 convolution](img/resnet-block.svg)  -->\n","\n","![Left: regular ResNet block; Right: ResNet block with 1x1 convolution.](https://drive.google.com/uc?export=view&id=1oKGT5iabWYLT7pUlMZOCX4-Drr3IttVZ)   \n","\n","\n","* Ignore BatchNorm for now."]},{"cell_type":"markdown","metadata":{"id":"AihDC_rF_nwn"},"source":["# ResNet Macro-Block\n","\n","* ResNet uses modules also called Macro-Blocks each of which containes several residual blocks. \n","\n","* In the first residual block within a Macro-Block, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n","\n","* In the remaining residual blocks, the number of channels remains the same\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E660w9QEVZeP"},"source":["# ResNet-18 -- Overview of architecture\n","\n","* We will consider here the implementation of the smallest ResNet, called ResNet-18.\n","* ResNet-18 (and all other ResNets) has 1 stem and 4 macro-modules followed by 1 linear (FC) layer. \n","* Stem = simple processing unit with 1 standard conv. layer (with stride 2) and 1 max pool (with stride 2).\n","    * Reduces input resolution from 224 to 112 and then to 56.\n","        * Nothing special so far.\n","* Each macro-module processes features in a different resolution. \n","     * Resolutions used are: 56, 28, 14, 7\n","* The macro-modules are composed of the so-called **ResNet blocks**\n","    * In ResNet-18, there are 2 ResNet blocks per macro-module\n","* Each ResNet (Residual) block consists of 2 convolutions with skip connections\n","    * Actually, the ResNet block is what He proposed in his paper  \n","* In total $1 + 4\\times2\\times2 + 1=18$ layers\n","    * That's why it's called ResNet-18\n","    * Different blocks per macro-module results in different models like the 152-layer ResNet-152\n"]},{"cell_type":"markdown","metadata":{"id":"is4xltPIVZeS"},"source":["# Batch Normalization\n","\n","* Batch Normalization (BN) is a popular and effective technique that consistently accelerates the convergence of deep nets.\n","* Together with residual blocks, BN made it possible to routinely train networks with over 100 layers."]},{"cell_type":"markdown","metadata":{"id":"6A3gaUm4VZeS"},"source":["# Batch Normalization\n","\n","* Batch normalization is applied to individual layers and works as follows:\n","    * In each training iteration (i.e. for each mini-batch), we normalize each channel of the input feature tensor seperately by subtracting their mean and dividing by their standard deviation (std).\n","        * Mean and std are estimated based on the statistics of the current minibatch.\n","    * Next, we apply a scaling coefficient and a scaling offset."]},{"cell_type":"markdown","metadata":{"id":"uPt3KmeBVZeS"},"source":["# Batch Normalization\n","\n","\n","* Denoting a particular minibatch by $\\mathcal{B}$, we firstly calculate $\\hat{\\mathbf{\\mu}}_\\mathcal{B}$ and $\\hat\\sigma_\\mathcal{B}$ as follows:\n","$$\\hat{\\mathbf{\\mu}}_\\mathcal{B} \\leftarrow \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x}\n","\\text{ and }\n","\\hat{\\mathbf{\\sigma}}_\\mathcal{B}^2 \\leftarrow \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\mathbf{\\mu}_{\\mathcal{B}})^2 + \\epsilon$$\n","    * There's a different mean and std per channel.\n","    * A small constant $\\epsilon > 0$ is added to ensure that we never attempt division by zero.\n","\n","* BN transforms the activations at a given feature tensor $\\mathbf{x}$\n","according to the following expression:\n","$$\\mathrm{BN}(\\mathbf{x}) = \\mathbf{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\mathbf{\\mu}}_\\mathcal{B}}{\\hat\\sigma_\\mathcal{B}} + \\mathbf{\\beta}$$\n","   * The above formula is applied *channelwise* i.e. there's a different mean and std per channel.\n","    \n","* After normalization, the resulting minibatch of activations has zero mean and unit variance. Because this is an arbitrary choice, we commonly include channel-wise scaling coefficients $\\mathbf{\\gamma}$ and offsets $\\mathbf{\\beta}$.\n","    * These are learnable parameters learnt via back-propagation!\n","\n"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}