{"cells":[{"cell_type":"code","source":["# Setting up google drive \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"],"metadata":{"id":"5dPDSSOllrUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKJRukyjTeTR"},"outputs":[],"source":["import my_utils as mu\n","import torch\n","from torch import nn"]},{"cell_type":"markdown","metadata":{"id":"ZHMsemHLTeTU","origin_pos":0},"source":["# Convolutional Neural Networks -- LeNet\n","\n","* **LeNet** is the first published CNNs\n","* The model was introduced by Yann LeCun, then a researcher at AT&T Bell Labs, for recognizing handwritten digits in images \n","* In 1989, LeCun published the first study to successfully train CNNs via backpropagation.\n","* At the time LeNet achieved outstanding results matching the performance of support vector machines, then a dominant approach in supervised learning.\n","* LeNet was eventually adapted to recognize digits for processing deposits in ATM machines.\n"]},{"cell_type":"markdown","metadata":{"id":"Gh0thI17TeTU"},"source":["# LeNet\n","\n","* At a high level, LeNet (LeNet-5) consists of 2 parts:\n","    1. a convolutional encoder consisting of two convolutional layers; and\n","    2. a dense block consisting of three fully-connected layers;\n","\n","<!-- ![Data flow in LeNet. The input is a handwritten digit, the output a probability over 10 possible outcomes.](img/lenet.svg)  -->\n","\n","![Data flow in LeNet. The input is a handwritten digit, the output a probability over 10 possible outcomes.](https://drive.google.com/uc?export=view&id=18Kd-JNGeKp38qAVEuxEyYU7rjNudWdWA) \n","\n"]},{"cell_type":"markdown","metadata":{"id":"uUTBAukyTeTV"},"source":["# LeNet -- Convolutional Encoder\n","\n","* Each convolutional *block*: \n","    * A convolutional layer.\n","    * A sigmoid activation function (ReLUs were discovered recently).\n","    * A subsequent average pooling operation (max pooling was discovered later).\n","* Each convolutional layer uses a $5\\times 5$ kernel.\n","* The first convolutional layer has 6 output channels, while the second has 16.\n","* Each $2\\times2$ pooling operation (stride 2) reduces dimensionality by a factor of $4$ via spatial downsampling.\n","* The convolutional block emits an output with shape given by (batch size, number of channel, height, width).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U1e7kHElTeTV"},"source":["# LeNet -- Dense Block\n","\n","* In order to pass output from the convolutional block to the dense block, we must flatten each example in the minibatch.\n","* In other words, we take the four-dimensional input and transform it into the two-dimensional input expected by fully-connected layers:\n","    * the two-dimensional representation that we desire has uses the first dimension to index examples in the minibatch\n","    * the second to give the flat vector representation of each example.\n","* LeNet's dense block has three fully-connected layers, with 120, 84, and 10 outputs, respectively.\n","    * Because we are still performing classification, the 10-dimensional output layer corresponds to the number of possible output classes."]},{"cell_type":"markdown","metadata":{"id":"6fWxaKgJTeTW"},"source":["# Compressed LeNet Representation \n","\n","\n","<!-- ![Compressed notation for LeNet-5.](img/lenet-vert.svg) -->\n","\n","![Compressed notation for LeNet-5.](https://drive.google.com/uc?export=view&id=1Oh-SnOYVTCH0WZGbsGqzo1Mju6TYC8ue)\n"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}