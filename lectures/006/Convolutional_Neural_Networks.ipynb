{"cells":[{"cell_type":"markdown","metadata":{"id":"J-hScMT2Sx_a","origin_pos":0},"source":["# Convolutional Neural Networks\n","\n","* Convolutional Neural Networks (CNNs) are special type of NNs particularly suitable for images (e.g. 2D, 3D, 4D).\n","* Nowdays, CNNs are also the NN of choice for 1D sequential signals, such as audio, text, and time series.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zGEv3qGfSx_j"},"source":["# Why CNNs\n","\n","* So far we considered NNs comprised of Fully Connected layers.\n","* An FC layer is not suitable for images.\n","* E.g.: Assume a 2D grayscale image (1 channel) of resolution $256 \\times 256$:\n","    * A single neuron connected to all pixels will require $256^2 = 65K$ params\n","        * If first layer: 128 of those neurons, in total $65 \\times 128 \\approx 9M$ params ! "]},{"cell_type":"markdown","metadata":{"id":"XxGU148Wk7-j"},"source":["# Convolutional Layer in a nutshell\n","    \n"," * Divide the image into $3\\times3$ windows. \n"," * Apply the same FC layer to all windows.\n"," * A single neuron will now have $3\\times3$ params, and the whole layer $9 \\times 128 \\approx 1K$ params!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dtoa5Lk4Sx_j"},"source":["# The Convolution Operation\n","\n","* Convolutional layers are a misnomer, since they are based on Cross-Correlation operations\n","* Abusing terminolodgy we will assume Convolution = Cross-Correlation.\n","* Example: Assume the input is a matrix (i.e. two-dimensional tensor) of size (shape) $3 \\times 3$ or ($3$, $3$).\n","* Assume a neuron (also called *convolutional kernel*) of size $2 \\times 2$.\n","\n","<!-- ![Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](img/correlation.svg)  -->\n","\n","![Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](https://drive.google.com/uc?export=view&id=1kaHHeWTN7gqJU7g9xDMiwAIU8fgI4RXN) \n","\n","* The output of the convolution operation between the input and the kernel is a matrix of $2 \\times 2$.\n","* To calculate the first (top-left) output value, we position the kernel at at the top-left corner of the input tensor. \n","* Then we multiple element-wise the elements of the kernel with the correponding elements of the input, and then sum:\n","\n","$$\n","0\\times0+1\\times1+3\\times2+4\\times3=19\n","$$\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"H_tj-lRASx_k"},"source":["# The Convolution Operation\n","\n","\n","![Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](img/correlation.svg) \n","\n","<!-- ![Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](https://drive.google.com/uc?export=view&id=1kaHHeWTN7gqJU7g9xDMiwAIU8fgI4RXN) --> \n","\n","* To calculate the remaining output values: we slide the kernel across the input tensor, from left to right and top to bottom. Each time we repeat the same calculation. The remaining 3 outputs are given by:\n","\n","$$\n","1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n","3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n","4\\times0+5\\times1+7\\times2+8\\times3=43.\n","$$\n","\n","\n","* Note that along each axis, the output size is slightly smaller than the input size. Because the kernel has width and height greater than one, we can only properly compute the convolution operation only for locations where the kernel fits wholly within the image.\n","* The output size is given by the input size $n_h \\times n_w$ minus the size of the convolution kernel $k_h \\times k_w$ via :\n","\n","$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dnxm0v-FSx_l"},"source":["# Padding\n","\n","* As described above, one tricky issue when applying convolutional layers is that we tend to lose pixels on the perimeter of our image.\n","* Since we typically use small kernels, for any given convolution, we might only lose a few pixels, but this can add up as we apply many successive convolutional layers.\n","* One straightforward solution to this problem is to add extra pixels of filler around the boundary of our input image, thus increasing the effective size of the image.\n","* Typically, we set the values of the extra pixels to zero.\n","* In the example below we pad a $3 \\times 3$ input, increasing its size to $5 \\times 5$. The corresponding output then increases to a $4 \\times 4$ matrix.\n","\n","\n"," <!-- ![Two-dimensional cross-correlation with padding.](img/conv-pad.svg)  -->\n","\n","![Two-dimensional cross-correlation with padding.](https://drive.google.com/uc?export=view&id=1jADQ3kjHX9Hcw5lsBhVpr2Gi31NNiwbH)  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"G3vJUkSGSx_l"},"source":["# Padding\n","\n","* In general, if we add a total of $p_h$ rows of padding (roughly half on top and half on bottom) and a total of $p_w$ columns of padding (roughly half on the left and half on the right), the output shape will be\n","\n","$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1).$$\n","\n","* This means that the height and width of the output will increase by $p_h$ and $p_w$, respectively.\n","\n","* In many cases, we will want to set $p_h=k_h-1$ and $p_w=k_w-1$ to give the input and output the same height and width.\n","\n","* CNNs commonly use convolution kernels with odd height and width values, such as 1, 3, 5, or 7. Choosing odd kernel sizes has the benefit that we can preserve the spatial dimensionality while padding with the same number of rows on top and bottom, and the same number of columns on left and right.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yT2EGYuSSx_m"},"source":["# Stride\n","\n","* When computing the convolution, we start with the convolution window at the top-left corner of the input tensor, and then slide it over all locations both down and to the right.\n","* In previous examples, we default to sliding one element at a time.\n","* However, sometimes, because we wish to downsample, we move our window more than one element at a time, skipping the intermediate locations.\n","* We refer to the number of rows and columns traversed per slide as the *stride*.\n","* So far, we have used strides of 1, both for height and width.\n","* An example with stride 2:\n","\n","<!-- ![Cross-correlation with strides of 3 and 2 for height and width, respectively.](img/conv-stride.svg) -->\n","\n","![Cross-correlation with strides of 3 and 2 for height and width, respectively.](https://drive.google.com/uc?export=view&id=19GGEuicikR4FhMy1k4R3zbriwIz7c3us)\n"]},{"cell_type":"markdown","metadata":{"id":"LUiKiyNXSx_m"},"source":["# Multiple Input and Multiple Output Channels\n","\n","* Until now, we simplified all of our numerical examples by working with just a single input and a single output channel.\n","* This has allowed us to think of our inputs, convolution kernels, and outputs each as two-dimensional tensors.\n","\n","* When we add channels into the mix, our inputs and outpus  both become three-dimensional tensors.\n","* For example, each RGB input image has shape $3\\times h\\times w$.\n","* We refer to this axis, with a size of 3, as the *channel* dimension.\n","* We will take a deeper look at convolution kernels with multiple input and multiple output channels."]},{"cell_type":"markdown","metadata":{"id":"4-dRjIxkSx_n"},"source":["# Multiple Input Channels\n","\n","* When the input data contain multiple channels, we need to construct a convolution kernel with the same number of input channels as the input data\n","\n","* Assuming that the number of channels for the input data is $c_i$, the number of input channels of the convolution kernel also needs to be $c_i$. \n","* If our convolution kernel's window shape is $k_h\\times k_w$, then when $c_i=1$, we can think of our convolution kernel as just a two-dimensional tensor of shape $k_h\\times k_w$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2ZRTZfkhk7-o"},"source":["* However, when $c_i>1$, we need a kernel that contains a tensor of shape $k_h\\times k_w$ for *every* input channel. Concatenating these $c_i$ tensors together yields a convolution kernel of shape $c_i\\times k_h\\times k_w$.\n","* Since the input and convolution kernel each have $c_i$ channels, we can perform a cross-correlation operation on the two-dimensional tensor of the input and the two-dimensional tensor of the convolution kernel for each channel, adding the $c_i$ results together (summing over the channels) to yield a two-dimensional tensor.\n","* This is the result of a two-dimensional convolution between a multi-channel input and a multi-input-channel convolution kernel.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zOfOxCAQSx_n"},"source":["# Multiple Input Channels\n","\n","* An example of a two-dimensional convolution with two input channels:\n","\n","<!-- ![Cross-correlation computation with 2 input channels.](img/conv-multi-in.svg)  -->\n","\n","![Cross-correlation computation with 2 input channels.](https://drive.google.com/uc?export=view&id=1Yd-xHXE5RuxpwMw8dFMyTK_wOcclEhud) \n","\n","* The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation:\n","$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$."]},{"cell_type":"markdown","metadata":{"id":"V3Y40FK_Sx_o"},"source":["# Multiple Output Channels\n","\n","* Regardless of the number of input channels, so far we always ended up with one output channel.\n","* However, it turns out to be essential to have multiple channels at each layer.\n","* In the most popular neural network architectures, we actually increase the channel dimension as we go deeper in the neural network, typically downsampling to trade off spatial resolution for greater *channel depth*.\n","* Intuitively, you could think of each channel as responding to some different set of features.\n","    * In reality features are not learned independent but are optimized to be jointly useful.\n","        * E.g.: it may not be that a single channel learns an edge detector\n"]},{"cell_type":"markdown","metadata":{"id":"f58pQGLLk7-p"},"source":["* Denote by $c_i$ and $c_o$ the number of input and output channels, respectively, and let $k_h$ and $k_w$ be the height and width of the kernel.\n","* To get an output with multiple channels, we repeat the single output case $c_o$ times with $c_o$ different kernels and then concatenate the $c_o$ different outputs. \n","    * We create a kernel tensor of shape $c_i\\times k_h\\times k_w$ for *every* output channel.\n","\n","* All $c_o$ different kernels can be put together, in a 4D tensor of size $c_o\\times c_i\\times k_h\\times k_w$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5YBzcgVwk7-p"},"source":["# Receptive field\n","\n","* The receptive field refers to the area that is used to calculate the output of a convolution.\n","* By stacking many conv. layers the effective receptive field increases.\n","    * This is why we need models with **many Conv. Layers**!\n","\n","<img src=\"img/receptive.png\" alt=\"drawing\" width=\"350\"/> \n","\n","* The receptive field of each convolution layer with a 3x3 kernel. The green area marks the receptive field of one pixel in Layer 2, and the yellow area marks the receptive field of one pixel in Layer 3.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6aQ4oWwgSx_o"},"source":["# Pooling\n","\n","* **Maximum pooling** and **average pooling**:\n","    * a fixed-shape window is slid over all regions of the input tensor\n","    * At each location that the pooling window hits, it computes the maximum or average value of the input subtensor in the window,\n","\n","\n"," <!-- ![Maximum pooling with a pooling window shape of $2\\times 2$. The shaded portions are the first output element as well as the input tensor elements used for the output computation: $\\max(0, 1, 3, 4)=4$.](img/pooling.svg)  -->\n","\n","![Maximum pooling with a pooling window shape of $2\\times 2$. The shaded portions are the first output element as well as the input tensor elements used for the output computation: $\\max(0, 1, 3, 4)=4$.](https://drive.google.com/uc?export=view&id=1ln9RWKxwadccM2PUMGJYuVu0n8amQ5Cz)  \n","\n","\n","\n","* The output tensor has a height of 2 and a width of 2. The four elements are derived from the maximum value in each pooling window:\n","\n","$$\n","\\max(0, 1, 3, 4)=4,\\\\\n","\\max(1, 2, 4, 5)=5,\\\\\n","\\max(3, 4, 6, 7)=7,\\\\\n","\\max(4, 5, 7, 8)=8.\\\\\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"SE0KPk4ySx_p"},"source":["# Why pooling?\n","\n","* With pooling we gradually reduce the spatial resolution of our features, aggregating information so that the deeper we go in the network, the larger the receptive field (in the input) to which each hidden node is sensitive.\n","\n","* Often our ultimate task asks some global question about the image, e.g., *does it contain a cat?*\n","    * So typically the units of our final layer should be sensitive to the entire input.\n","    * By gradually aggregating information, yielding coarser and coarser maps, we accomplish this goal of ultimately learning a global representation"]},{"cell_type":"markdown","metadata":{"id":"jZsn6Wg5Sx_p"},"source":["# Summary\n"," \n","* Convolutional filters are like small neurons used to scan the image.\n","* A convolutional filter has as many channels as the number of channels of the input feature map.\n","* The number of channels of the output feature map is equal to the number of convolutional filters of the convolutional layer\n","* With pooling we gradually reduce the spatial resolution of our features"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}